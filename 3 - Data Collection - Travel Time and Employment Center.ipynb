{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singapore Public Housing (HDB) Resale Price Prediction Model (Part 3)\n",
    "### Data Collection - Travel Time and Employment Center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. About this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the amenities and infrastructure near a property has an effect on the sale price, its proximity to the major employment center would have influence on the the price tag of property in a certain areas. In this notebook, we will collect travel time from each property transaction record to 5 different employment center in Singapore,\n",
    "\n",
    "1. **Raffles Place** - Center Business District (CBD) of Singapore, home to major financial institution and business services\n",
    "2. **one-north** - Industrial Park dedicated for research and innovation for biomedical and tech and media-related corporation and start-ups\n",
    "3. **Jurong East** - Dubbed as the 2nd CBD of Singapore, in close proximity to heavy-industry and petrochemical zone of Jurong and Tuas\n",
    "4. **Orchard** - Retail center of Singapore, lined with plethora of high-end shopping malls and hotels\n",
    "5. **Changi** - International Airport of Singapore, one of the largest transporation hub in the Eastern Hemisphere\n",
    "\n",
    "For the travel time, we will be looking into 2 aspects: travelling by public transport and by driving. Majority of the workforce in Singapore are commuting to work by public transport, however it would be interesting to observe the effect of each travelling mode on property prices. The data will be acquired from OneMap private API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Vanilla Libraries\n",
    "import requests, json, time, random, math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrt = pd.read_csv('./Dataset/Engineered/MRT.csv')\n",
    "hdb = pd.read_csv('./Dataset/Transitional/complete_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Unique Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to what we did in Part 1, we will be using unique coordinates in the core HDB dataset only for API call. It would save up more than 80% of time and mitigate the possibility of getting different coordinates for the same coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Employment Center of Singapore\n",
    "r_place = mrt[mrt['Name']=='Raffles Place']\n",
    "o_north = mrt[mrt['Name']=='one-north']\n",
    "j_east= mrt[mrt['Name']=='Jurong East']\n",
    "orchard = mrt[mrt['Name']=='Orchard']\n",
    "changi = mrt[mrt['Name']=='Changi Airport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting only unique coordinates from HDB dataset to cut short mining time\n",
    "coors = [coor for coor in zip(hdb['latitude'], hdb['longitude'])]\n",
    "coors_unique = pd.Series(coors).unique()\n",
    "coors_unique = pd.Series(coors_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to DataFrame\n",
    "coors_df = pd.DataFrame(coors_unique, columns=['coordinates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1.362004539, 103.85387990000001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.370966352, 103.83820190000002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1.38070883, 103.8353682)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1.3662010409999998, 103.857201)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1.381041355, 103.8351317)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         coordinates\n",
       "0  (1.362004539, 103.85387990000001)\n",
       "1  (1.370966352, 103.83820190000002)\n",
       "2          (1.38070883, 103.8353682)\n",
       "3   (1.3662010409999998, 103.857201)\n",
       "4         (1.381041355, 103.8351317)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv for function get_pt_travel_time\n",
    "coors_df.to_csv('./Dataset/Engineered/Travel_time.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Public Transport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the API calling, we have build a function that can be used for public transport and driving travel data. Since OneMap dedicated the feature of getting travel data as part of its private API, OneMap account would need to be created if you would like to try the code. After which, token would need to be retrieved for the API to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TOKEN - TO BE UPDATED WITH YOUR OWN VALUE ###\n",
    "token = \"your_onemap_private_api_token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract travel time (PT or Driving) by OneMap API\n",
    "def get_pt_travel_time(desti_df, column_name, route_type='pt'):\n",
    "    coors_df = pd.read_csv('./Dataset/Engineered/Travel_time.csv')\n",
    "\n",
    "    coors_list = coors_df['coordinates'].str.replace('(', '').str.replace(')', '').str.split(', ')\n",
    "    \n",
    "    if column_name not in coors_df.columns:\n",
    "        coors_df[column_name] = np.nan\n",
    "\n",
    "    for idx, coors in enumerate(coors_list):\n",
    "        if math.isnan(coors_df.loc[idx, column_name]):\n",
    "            start = coors[0], coors[1]\n",
    "            end = desti_df['Latitude'].values[0], desti_df['Longitude'].values[0]\n",
    "\n",
    "            print('\\rWaiting... {} completed... {} entries remaining... '.format(idx, len(coors_df)-idx-1), end='.')\n",
    "\n",
    "            if route_type == 'pt':\n",
    "                query = f\"\"\"https://developers.onemap.sg/privateapi/routingsvc/route?start={start[0]},{start[1]}&end={end[0]},{end[1]}&routeType={route_type}&token={token}&date=2019-10-04&time=07:30:00&mode=TRANSIT&maxWalkDistance=500&numItineraries=1\"\"\".replace('\\n', '')\n",
    "            \n",
    "            else:\n",
    "                query = f\"\"\"https://developers.onemap.sg/privateapi/routingsvc/route?start={start[0]},{start[1]}&end={end[0]},{end[1]}&routeType={route_type}&token={token}\"\"\" \n",
    "                \n",
    "            try:\n",
    "                response = requests.get(query)\n",
    "                jsons = json.loads(response.content)\n",
    "                \n",
    "                if route_type == 'pt':\n",
    "                    duration = round(jsons['plan']['itineraries'][0]['duration']/60, 2)\n",
    "                else:\n",
    "                    duration = round(jsons['route_summary']['total_time']/60, 2)\n",
    "                    \n",
    "                coors_df.loc[idx, column_name] = duration\n",
    "\n",
    "            except:\n",
    "                coors_df.loc[idx, column_name] = np.nan\n",
    "\n",
    "            coors_df.to_csv('./Dataset/Engineered/Travel_time.csv', index=False)\n",
    "\n",
    "            time.sleep(random.randint(1, 2)/4)\n",
    "            \n",
    "    if coors_df[column_name].isnull().sum() == 0:\n",
    "        print(\"--- Data is complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will start collecting data for public transport option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data is complete ---\n"
     ]
    }
   ],
   "source": [
    "# Raffles Place by Public Transport\n",
    "get_pt_travel_time(r_place, 'raffles_place_dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data is complete ---\n"
     ]
    }
   ],
   "source": [
    "# One North by Public Transport\n",
    "get_pt_travel_time(o_north, 'one_north_dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data is complete ---\n"
     ]
    }
   ],
   "source": [
    "# Jurong East by Public Transport\n",
    "get_pt_travel_time(j_east, 'jurong_east_dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data is complete ---\n"
     ]
    }
   ],
   "source": [
    "# Orchard by Public Transport\n",
    "get_pt_travel_time(orchard, 'orchard_dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data is complete ---\n"
     ]
    }
   ],
   "source": [
    "# Changi by Public Transport\n",
    "get_pt_travel_time(changi, 'changi_dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coordinates            0\n",
       "raffles_place_dist     0\n",
       "one_north_dist         0\n",
       "jurong_east_dist       0\n",
       "orchard_dist           0\n",
       "changi_dist            0\n",
       "raffles_place_drive    0\n",
       "one_north_drive        0\n",
       "jurong_east_drive      0\n",
       "orchard_drive          0\n",
       "changi_drive           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check on missing data\n",
    "coors_df = pd.read_csv('./Dataset/Engineered/Travel_time.csv')\n",
    "coors_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Driving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have no missing value in the public transport data, we will now proceed to driving data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data is complete ---\n"
     ]
    }
   ],
   "source": [
    "# Raffles Place by Driving\n",
    "get_pt_travel_time(r_place, 'raffles_place_drive', route_type='drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data is complete ---\n"
     ]
    }
   ],
   "source": [
    "# One North by Driving\n",
    "get_pt_travel_time(o_north, 'one_north_drive', route_type='drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data is complete ---\n"
     ]
    }
   ],
   "source": [
    "# Jurong East by Driving\n",
    "get_pt_travel_time(j_east, 'jurong_east_drive', route_type='drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data is complete ---\n"
     ]
    }
   ],
   "source": [
    "# Orchard by Driving\n",
    "get_pt_travel_time(orchard, 'orchard_drive', route_type='drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data is complete ---\n"
     ]
    }
   ],
   "source": [
    "# Changi by Driving\n",
    "get_pt_travel_time(changi, 'changi_drive', route_type='drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "coors_df = pd.read_csv('./Dataset/Engineered/Travel_time.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is complete, we can finally merge the data by its coordinates and export to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'coordinates' column for merging with travel_time dataframe\n",
    "hdb['coordinates'] = '(' + hdb['latitude'].astype(str) + ', ' + hdb['longitude'].astype(str) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Merging\n",
    "hdb = pd.merge(hdb, coors_df, how='left', on='coordinates').drop('coordinates', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export final dataframe\n",
    "hdb.to_csv('./Dataset/Transitional/complete_data_with_ec.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook would mark the end of the Data Collection process of our project. Next up, on the 4th notebook, we will be looking into extracting highway data from geojson object."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
