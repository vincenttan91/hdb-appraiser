{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singapore Public Housing (HDB) Resale Price Prediction Model (Part 5)\n",
    "### Feature Engineering - Geospatial Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. About this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the information or data we need for the analysis on housing price, we can now focus on the feature engineering of our core HDB dataset. In this notebook, we will be performing calculation on each HDB transaction record to get their respective geospatial feature. Due to the heavy calculation from looping through many points, the code will run for a relatively long time - recorded 30 minutes the last time it was ran."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import vanilla libraries for data science\n",
    "import pandas as pd\n",
    "\n",
    "# Import geospatial libraries\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "pd.set_option('max_columns', 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb = pd.read_csv('./Dataset/Transitional/complete_data_with_ec.csv')\n",
    "mrt = pd.read_csv('./Dataset/Engineered/MRT.csv')\n",
    "bus = pd.read_csv('./Dataset/Engineered/Bus_Stop.csv')\n",
    "pri = pd.read_csv('./Dataset/Engineered/Primary_School.csv')\n",
    "sec = pd.read_csv('./Dataset/Engineered/Secondary_School.csv')\n",
    "spm = pd.read_csv('./Dataset/Engineered/Mall.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since almost all the operations involved calculation of distance, a function is created to keep the code DRY and easier to read and comprehend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate naive-Haversine distance between 2 coordinates\n",
    "def dist_cal(coor_1, coor_2):\n",
    "    R = 6373\n",
    "    lat_1 = radians(coor_1[0])\n",
    "    lon_1 = radians(coor_1[1])   \n",
    "    lat_2 = radians(coor_2[0])\n",
    "    lon_2 = radians(coor_2[1])\n",
    "    dlon = lon_2 - lon_1\n",
    "    dlat = lat_2 - lat_1\n",
    "    a = sin(dlat / 2)**2 + cos(lat_1) * cos(lat_2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = int(R * c * 1000)\n",
    "    return int(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MRT Stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the MRT stations, we will be collecting 4 features:\n",
    "1. **mrt_dist** - Distance from the nearest MRT\n",
    "2. **mrt_station** - Name of the nearest MRT, this is only for sample checking purpose\n",
    "3. **near_bus_itc** - Binary indicating whether the property is within 500m of a bus interchange\n",
    "4. **near_mrt_itc** - Binary indicating whether the property is within 500m of a MRT interchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 39s, sys: 1.1 s, total: 2min 40s\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for idx_1, coor_1 in enumerate(zip(hdb['latitude'], hdb['longitude'])):\n",
    "    dist_list = []\n",
    "    \n",
    "    for coor_2 in zip(mrt['Latitude'], mrt['Longitude']):\n",
    "        dist_list.append(dist_cal(coor_1, coor_2))\n",
    "        \n",
    "    hdb.loc[idx_1, 'mrt_dist'] = min(dist_list)\n",
    "    \n",
    "    nearest = dist_list.index(min(dist_list))\n",
    "    hdb.loc[idx_1, 'mrt_station'] = mrt.loc[nearest, 'Name']\n",
    "    \n",
    "    if (mrt.loc[nearest, 'Bus_Interchange'] == 1) & (min(dist_list) <= 500):\n",
    "        hdb.loc[idx_1, 'near_bus_itc'] = 1\n",
    "    else:\n",
    "        hdb.loc[idx_1, 'near_bus_itc'] = 0\n",
    "    \n",
    "    if (mrt.loc[nearest, 'MRT_Interchange'] == 1) & (min(dist_list) <= 500):\n",
    "        hdb.loc[idx_1, 'near_mrt_itc'] = 1\n",
    "    else:\n",
    "        hdb.loc[idx_1, 'near_mrt_itc'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bus Stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the bus stop data, we will be collecting only 2 pieces of information:\n",
    "1. **bus_u300m** - Number of bus stops in 300m radius (presumed acceptable walking distance)\n",
    "2. **bus_dist** - Distance to the nearest bus stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 9s, sys: 2.01 s, total: 10min 11s\n",
      "Wall time: 10min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx_1, coor_1 in enumerate(zip(hdb['latitude'], hdb['longitude'])):\n",
    "    dist_list = []\n",
    "    bus_list = 0\n",
    "    for coor_2 in zip(bus['latitude'], bus['longitude']):\n",
    "        distance = dist_cal(coor_1, coor_2)\n",
    "        dist_list.append(distance)\n",
    "        if distance <= 300:\n",
    "            bus_list += 1\n",
    "    hdb.loc[idx_1, 'bus_u300m'] = bus_list\n",
    "    hdb.loc[idx_1, 'bus_dist'] = min(dist_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Shopping Malls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar to the bus stops data, for the shopping mall data, we will be calculating for:\n",
    "1. **mall_u1km** - Number of shopping malls within 1km radius (10 mins commuting time)\n",
    "2. **mall_dist** - Distance to the nearest shopping mall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.5 s, sys: 198 ms, total: 59.7 s\n",
      "Wall time: 59.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx_1, coor_1 in enumerate(zip(hdb['latitude'], hdb['longitude'])):\n",
    "    dist_list = []\n",
    "    total_list = []\n",
    "    \n",
    "    for coor_2 in zip(spm['latitude'], spm['longitude']):\n",
    "        distance = dist_cal(coor_1, coor_2)\n",
    "        total_list.append(distance)\n",
    "        if distance <= 1000:\n",
    "            dist_list.append(distance)\n",
    "            \n",
    "    hdb.loc[idx_1, 'mall_u1km'] = len(dist_list)\n",
    "    hdb.loc[idx_1, 'mall_dist'] = min(total_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Primary School"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the primary school data, we are assuming the top 20 schools are considered as 'elite'. Under this section, we will be calculating for the following feature:\n",
    "1. **pri_u1km** - Number of primary school in 1km radius\n",
    "2. **pri_u2km** - Number of primary school in 2km radius\n",
    "3. **pri_aff_u1km** - Number of primary school with affiliation in 1km radius\n",
    "4. **pri_aff_u2km** - Number of primary school with affiliation in 2km radius\n",
    "5. **pri_elite_u1km** - Number of elite primary school in 1km radius\n",
    "6. **pri_elite_u2km** - Number of elite primary school in 2km radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marking the top 20 schools as elite\n",
    "pri.loc[0:19, 'elite'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 48s, sys: 589 ms, total: 2min 48s\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx_1, coor_1 in enumerate(zip(hdb['latitude'], hdb['longitude'])):\n",
    "    under_1km = 0\n",
    "    under_2km = 0\n",
    "    aff_1km = 0\n",
    "    aff_2km = 0\n",
    "    elite_1km = 0\n",
    "    elite_2km = 0\n",
    "\n",
    "    for idx_2, coor_2 in enumerate(zip(pri['latitude'], pri['longitude'])):\n",
    "        distance = dist_cal(coor_1, coor_2)\n",
    "        \n",
    "        if distance <= 1000:\n",
    "            under_1km+=1\n",
    "            if (pri.loc[idx_2, 'affiliation'] == 1) & (pri.loc[idx_2, 'elite'] == 1):\n",
    "                aff_1km+=1\n",
    "            if pri.loc[idx_2, 'elite'] == 1:\n",
    "                elite_1km+=1\n",
    "                \n",
    "        if distance <= 2000:\n",
    "            under_2km+=1\n",
    "            if (pri.loc[idx_2, 'affiliation'] == 1) & (pri.loc[idx_2, 'elite'] == 1):\n",
    "                aff_2km+=1\n",
    "            if pri.loc[idx_2, 'elite'] == 1:\n",
    "                elite_2km+=1\n",
    "            \n",
    "    hdb.loc[idx_1, 'pri_u1km'] = under_1km\n",
    "    hdb.loc[idx_1, 'pri_u2km'] = under_2km\n",
    "    hdb.loc[idx_1, 'pri_aff_u1km'] = aff_1km\n",
    "    hdb.loc[idx_1, 'pri_aff_u2km'] = aff_2km\n",
    "    hdb.loc[idx_1, 'pri_elite_u1km'] = elite_1km\n",
    "    hdb.loc[idx_1, 'pri_elite_u2km'] = elite_2km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Secondary School"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with the primary school data, we made assumption that the top 20 secondary schools are considered as 'elite'. Under this section, we will be calculating for the following feature:\n",
    "1. **sec_u1km** - Number of secondary school in 1km radius\n",
    "2. **sec_u2km** - Number of secondary school in 2km radius\n",
    "3. **sec_aff_u1km** - Number of secondary school with affiliation in 1km radius\n",
    "4. **sec_aff_u2km** - Number of secondary school with affiliation in 2km radius\n",
    "5. **sec_elite_u1km** - Number of elite secondary school in 1km radius\n",
    "6. **sec_elite_u2km** - Number of elite secondary school in 2km radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marking the top 20 schools as elite\n",
    "sec.loc[0:19, 'elite'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 40s, sys: 645 ms, total: 2min 41s\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx_1, coor_1 in enumerate(zip(hdb['latitude'], hdb['longitude'])):\n",
    "    under_1km = 0\n",
    "    under_2km = 0\n",
    "    aff_1km = 0\n",
    "    aff_2km = 0\n",
    "    elite_1km = 0\n",
    "    elite_2km = 0\n",
    "\n",
    "    for idx_2, coor_2 in enumerate(zip(sec['latitude'], sec['longitude'])):\n",
    "        distance = dist_cal(coor_1, coor_2)\n",
    "        \n",
    "        if distance <= 1000:\n",
    "            under_1km+=1\n",
    "            if (sec.loc[idx_2, 'affiliation'] == 1) & (sec.loc[idx_2, 'elite'] == 1):\n",
    "                aff_1km+=1\n",
    "            if sec.loc[idx_2, 'elite'] == 1:\n",
    "                elite_1km+=1\n",
    "                \n",
    "        if distance <= 2000:\n",
    "            under_2km+=1\n",
    "            if (sec.loc[idx_2, 'affiliation'] == 1) & (sec.loc[idx_2, 'elite'] == 1):\n",
    "                aff_2km+=1\n",
    "            if sec.loc[idx_2, 'elite'] == 1:\n",
    "                elite_2km+=1\n",
    "            \n",
    "    hdb.loc[idx_1, 'sec_u1km'] = under_1km\n",
    "    hdb.loc[idx_1, 'sec_u2km'] = under_2km\n",
    "    hdb.loc[idx_1, 'sec_aff_u1km'] = aff_1km\n",
    "    hdb.loc[idx_1, 'sec_aff_u2km'] = aff_2km\n",
    "    hdb.loc[idx_1, 'sec_elite_u1km'] = elite_1km\n",
    "    hdb.loc[idx_1, 'sec_elite_u2km'] = elite_2km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Highways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the highway data, it is relatively simple, we are calculating the nearest distance from a property unit to a highway line vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculating nearest distance from all line vector and return the lowest\n",
    "def get_highway_dist(row, df):\n",
    "    distances = []\n",
    "    house = Point(row['longitude'], row['latitude'])\n",
    "    for highway in df['geometry']:\n",
    "        distances.append(int(highway.distance(house) * 100_000))\n",
    "    return min(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataframe and transform data into polygon/line-vector object\n",
    "highways = pd.read_csv('./Dataset/Spatial/Highways.csv')\n",
    "highways['geometry'] = highways['geometry'].apply(wkt.loads)\n",
    "highways = gpd.GeoDataFrame(highways, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.6 s, sys: 77.2 ms, total: 41.7 s\n",
      "Wall time: 41.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hdb['dist_to_highway'] = hdb.apply(get_highway_dist, df=highways, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Highway Exits/Ramps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as highway data, but we are calculating the distance to the nearest highway ramps/exits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataframe and transform data into polygon/line-vector object\n",
    "ramps = pd.read_csv('./Dataset/Spatial/Ramps.csv')\n",
    "ramps['geometry'] = ramps['geometry'].apply(wkt.loads)\n",
    "ramps = gpd.GeoDataFrame(ramps, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 51s, sys: 251 ms, total: 6min 51s\n",
      "Wall time: 6min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hdb['dist_to_exits'] = hdb.apply(get_highway_dist, df=ramps, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export to Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb.to_csv('./Dataset/Transitional/final_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final data is now complete, we may proceed to the analysis and modelling part. However, in the next part (Part 6), we will still be performing data wrangling for better visualization using maps. Feel free to skip to the final notebook (Part 7) if you are eager to find out what the data has shown."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
