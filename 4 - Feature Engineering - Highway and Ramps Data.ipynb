{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singapore Public Housing (HDB) Resale Price Prediction Model (Part 4)\n",
    "### Feature Engineering - Highway and Ramps Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. About this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noise could be an issue for home buyer when choosing a property to call home. While we cannot control what kind of neighbours we will get prior to moving in, we can choose not to be living close to major highway. Vehicle noise and emission might be a turn off for some people, so it might be interesting to find out if it has significant effect on the resale price of HDB unit.\n",
    "\n",
    "This notebook will be a relatively short one, it will focus only to extract information from geojson data and convert them into csv format that we can use for pandas transformation in the next part. The raw data of highway came from the Singapore national archive, where national map line of major expressway and trunk road are projected as line vector in geojson format. The archive can be found here in [this link](https://data.gov.sg/dataset/national-map-line?resource_id=de5f4fc2-e04f-4dcf-a02a-2ca6468b1b54).\n",
    "\n",
    "Part of this notebook was performed on Google Colab due to known dependencies issues with Geopandas. The code involving geopandas Geojson driver have been commented out for the ease of running the notebook without error. You may uncomment the code if you would like to test the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import JSON-related Libraries\n",
    "import json\n",
    "import geojson as gpd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file into dictionary for easier wrangling\n",
    "with open(\"./Dataset/Raw/national_map_line.geojson\", 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Layers/Contour_250K',\n",
       " 'Layers/Expressway',\n",
       " 'Layers/Expressway_Sliproad',\n",
       " 'Layers/International_bdy',\n",
       " 'Layers/Major_Road'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all possible categories of road in the geojson\n",
    "road_types = set()\n",
    "\n",
    "for polygon in data['features']:\n",
    "    string = polygon['properties']['Description']\n",
    "    road_type = BeautifulSoup(string, 'lxml').find_all(\"td\")[1].text\n",
    "    road_types.add(road_type)\n",
    "    \n",
    "road_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Highways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First up, we will extract all the polygon/line-vector object that has been marked as expressway and transform them into CSV format that we can use in pandas. However, due to the afore-mentioned dependencies issue, the object was required to be transformed into geojson file first so that it can be run on Google Colab. After that, it will be transformed to CSV file. The steps could actually be omitted if you face no dependencies issue with the Geopandas library or its Geojson driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all expressway polygon into a list\n",
    "highways = []\n",
    "for polygon in data['features']:\n",
    "    string = polygon['properties']['Description']\n",
    "    road_type = BeautifulSoup(string, 'lxml').find_all(\"td\")[1].text\n",
    "    if road_type == \"Layers/Expressway\":\n",
    "        highways.append(polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forming basic structure of geojson with the shortlisted expressway\n",
    "highway_json = data\n",
    "highway_json['features'] = highways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to geojson format for futher wranling in Google Colab\n",
    "with open(\"./Dataset/Spatial/highway_geojson.geojson\", 'w') as f:\n",
    "    json.dump(highway_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### ---      KNOWN DEPENDENCIES ISSUE      --- ###\n",
    "# ### ---  CODES TO EXPORT FOR GOOGLE COLAB  --- ###\n",
    "# ### ---     UNCOMMENT TO TEST THE CODE     --- ###\n",
    "\n",
    "# highways = gpd.read_file('./Dataset/Spatial/highway_geojson.geojson')\n",
    "# highways['Description'] = [BeautifulSoup(name, 'lxml').find('td').text for name in list(highways['Description'])]\n",
    "# highways.to_csv('./Dataset/Spatial/Highways.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Highway Exits/Ramps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same steps is repeated for highway exit/ramps data to extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all expressway ramps polygon into a list\n",
    "ramps = []\n",
    "for polygon in data['features']:\n",
    "    string = polygon['properties']['Description']\n",
    "    road_type = BeautifulSoup(string, 'lxml').find_all(\"td\")[1].text\n",
    "    if road_type == \"Layers/Expressway_Sliproad\":\n",
    "        ramps.append(polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forming basic structure of geojson with the shortlisted ramps\n",
    "ramp_json = data\n",
    "ramp_json['features'] = ramps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to geojson format for futher wranling in Google Colab\n",
    "with open(\"./Dataset/Spatial/ramp_geojson.geojson\", 'w') as f:\n",
    "    json.dump(ramp_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### ---      KNOWN DEPENDENCIES ISSUE      --- ###\n",
    "# ### ---  CODES TO EXPORT FOR GOOGLE COLAB  --- ###\n",
    "# ### ---     UNCOMMENT TO TEST THE CODE     --- ###\n",
    "\n",
    "# ramps = gpd.read_file('./Dataset/Spatial/ramp_geojson.geojson')\n",
    "# ramps['Description'] = [BeautifulSoup(name, 'lxml').find('td').text for name in list(ramps['Description'])]\n",
    "# ramps.to_csv('./Dataset/Spatial/Ramps.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have collected all the information that we need for the analysis. In the next notebook (Part 5), we will be performing feature engineering on the core HDB dataset to acquire all the geospatial information for each HDB transaction record."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
